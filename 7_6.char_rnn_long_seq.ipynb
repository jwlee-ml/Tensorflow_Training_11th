{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.nn import rnn_cell\n",
    "import numpy as np\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = (\"if you want to build a ship, don't drum up people together to \"\n",
    "            \"collect wood and don't assign them tasks and work, but rather \"\n",
    "            \"teach them to long for the endless immensity of the sea.\")\n",
    "\n",
    "char_set = list(set(sentence))\n",
    "char_dic = {w: i for i, w in enumerate(char_set)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dim = len(char_set)\n",
    "hidden_size = len(char_set)\n",
    "num_classes = len(char_set)\n",
    "sequence_length = 10  # Any arbitrary number\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, len(sentence) - sequence_length):\n",
    "    x_str = sentence[i:i + sequence_length]\n",
    "    y_str = sentence[i + 1: i + sequence_length + 1]\n",
    "    print(i, x_str, '->', y_str)\n",
    "\n",
    "    x = [char_dic[c] for c in x_str]  # x str to index\n",
    "    y = [char_dic[c] for c in y_str]  # y str to index\n",
    "\n",
    "    dataX.append(x)\n",
    "    dataY.append(y)\n",
    "\n",
    "batch_size = len(dataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.int32, [None, sequence_length])\n",
    "Y = tf.placeholder(tf.int32, [None, sequence_length])\n",
    "\n",
    "# One-hot encoding\n",
    "X_one_hot = tf.one_hot(X, num_classes)\n",
    "print(X_one_hot)  # check out the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a lstm cell with hidden_size (each unit output vector size)\n",
    "def lstm_cell():\n",
    "    cell = rnn_cell.LSTMCell(hidden_size, state_is_tuple=True)\n",
    "    return cell\n",
    "\n",
    "multi_cells = rnn_cell.MultiRNNCell([lstm_cell() for _ in range(2)], state_is_tuple=True)\n",
    "\n",
    "# outputs: unfolding size x hidden size, state = hidden size\n",
    "outputs, _states = tf.nn.dynamic_rnn(multi_cells, X_one_hot, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FC layer\n",
    "#X_for_fc = tf.reshape(outputs, [-1, hidden_size])\n",
    "outputs = tf.layers.dense(outputs, num_classes, activation=None)\n",
    "\n",
    "# reshape out for sequence_loss\n",
    "#outputs = tf.reshape(outputs, [batch_size, sequence_length, num_classes])\n",
    "\n",
    "#outputs = tf.layers.dense(outputs, num_classes, activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All weights are 1 (equal weights)\n",
    "weights = tf.ones([batch_size, sequence_length])\n",
    "\n",
    "sequence_loss = tf.contrib.seq2seq.sequence_loss(\n",
    "    logits=outputs, targets=Y, weights=weights)\n",
    "mean_loss = tf.reduce_mean(sequence_loss)\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth =True)))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(500):\n",
    "    _, l, results = sess.run(\n",
    "        [train_op, mean_loss, outputs], feed_dict={X: dataX, Y: dataY})\n",
    "    for j, result in enumerate(results):\n",
    "        index = np.argmax(result, axis=1)\n",
    "        #print(i, j, ''.join([char_set[t] for t in index]), l)\n",
    "\n",
    "# Let's print the last char of each result to check it works\n",
    "results = sess.run(outputs, feed_dict={X: dataX})\n",
    "for j, result in enumerate(results):\n",
    "    index = np.argmax(result, axis=1)\n",
    "    if j is 0:  # print all for the first result to make a sentence\n",
    "        print(''.join([char_set[t] for t in index]), end='')\n",
    "    else:\n",
    "        print(char_set[index[-1]], end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
